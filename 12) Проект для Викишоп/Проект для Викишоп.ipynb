{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Catboost\" data-toc-modified-id=\"Catboost-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Catboost</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.9/site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.21.1)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.9/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.9/site-packages (from catboost) (5.4.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.2.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from plotly->catboost) (8.0.1)\n",
      "Requirement already satisfied: langid in /opt/conda/lib/python3.9/site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from langid) (1.21.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from catboost import CatBoostClassifier\n",
    "import langid\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно отметить высокую степень дисбаланса классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая будет возвращать язык переданного ей текста, и применим ее к столбцу с комментариями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detector(row):\n",
    "  return langid.classify(row['text'])[0]\n",
    "\n",
    "df['language'] = df.apply(language_detector, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "  language  \n",
       "0       en  \n",
       "1       en  \n",
       "2       en  \n",
       "3       en  \n",
       "4       en  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    155664\n",
       "fr       343\n",
       "de       341\n",
       "es       288\n",
       "it       270\n",
       "       ...  \n",
       "mk         1\n",
       "uk         1\n",
       "ml         1\n",
       "bg         1\n",
       "ka         1\n",
       "Name: language, Length: 85, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, язык написания абсолютного большинства комментариев определен как англйиский."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая очищаяет и лемматизирует текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "\n",
    "def lemmatize_sent(text):\n",
    "    clear_text = ' '.join(re.sub(r'[^a-zA-Z ]', ' ', text['text']).split())\n",
    "    return str.lower(' '.join([lemmatizer.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(nltk.word_tokenize(clear_text))]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmas'] = df.apply(lemmatize_sent, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>language</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "  language                                             lemmas  \n",
       "0       en  explanation why the edits make under my userna...  \n",
       "1       en  d aww he match this background colour i m seem...  \n",
       "2       en  hey man i m really not try to edit war it s ju...  \n",
       "3       en  more i can t make any real suggestion on impro...  \n",
       "4       en  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['lemmas']\n",
    "target = df['toxic']\n",
    "\n",
    "features_train, features, target_train, target = train_test_split(features, target, test_size=.2, random_state=1)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features, target, test_size=.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим набор стоп-слов, которые будут исключены при векторизации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим векторайзер на обучающей выборке, затем преобразуем им обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "train_features_tf_idf = tf_idf.fit_transform(features_train)\n",
    "valid_features_tf_idf = tf_idf.transform(features_valid)\n",
    "test_features_tf_idf = tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера для модели логистической регрессии составила 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_features_tf_idf, target_train)\n",
    "predictions_logistic = model.predict(valid_features_tf_idf)\n",
    "print('F1-мера для модели логистической регрессии составила {:.2f}'.format(\n",
    "    f1_score(target_valid, predictions_logistic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы обратили внимание, что классы в датасете несбалансированы. Попробуем обучить модель со взвешенными классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера для модели логистической регрессии со взвешенными классами составила 0.73\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', max_iter=300)\n",
    "model.fit(train_features_tf_idf, target_train)\n",
    "predictions_logistic_balanced_weight = model.predict(valid_features_tf_idf)\n",
    "print('F1-мера для модели логистической регрессии со взвешенными классами составила {:.2f}'.format(\n",
    "    f1_score(target_valid, predictions_logistic_balanced_weight)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cb = df[['lemmas']]\n",
    "target_cb = df[['toxic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим выборки на обучающую, валидационную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cb_train, features_cb_, target_cb_train, target_cb_ = train_test_split(features_cb, target_cb, test_size=.2, random_state=1)\n",
    "features_cb_valid, features_cb_test, target_cb_valid, target_cb_test = train_test_split(features_cb_, target_cb_, test_size=.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6516775\ttest: 0.6514702\tbest: 0.6514702 (0)\ttotal: 4.61s\tremaining: 38m 18s\n",
      "50:\tlearn: 0.1528952\ttest: 0.1495818\tbest: 0.1495818 (50)\ttotal: 3m 53s\tremaining: 34m 16s\n",
      "100:\tlearn: 0.1324935\ttest: 0.1307348\tbest: 0.1307348 (100)\ttotal: 7m 43s\tremaining: 30m 30s\n",
      "150:\tlearn: 0.1249675\ttest: 0.1243189\tbest: 0.1243189 (150)\ttotal: 11m 40s\tremaining: 26m 58s\n",
      "200:\tlearn: 0.1200472\ttest: 0.1207664\tbest: 0.1207664 (200)\ttotal: 15m 28s\tremaining: 23m 1s\n",
      "250:\tlearn: 0.1159756\ttest: 0.1180268\tbest: 0.1180268 (250)\ttotal: 19m 13s\tremaining: 19m 4s\n",
      "300:\tlearn: 0.1126570\ttest: 0.1161610\tbest: 0.1161610 (300)\ttotal: 22m 58s\tremaining: 15m 11s\n",
      "350:\tlearn: 0.1100628\ttest: 0.1147212\tbest: 0.1147212 (350)\ttotal: 26m 46s\tremaining: 11m 21s\n",
      "400:\tlearn: 0.1074270\ttest: 0.1135209\tbest: 0.1135209 (400)\ttotal: 30m 27s\tremaining: 7m 31s\n",
      "450:\tlearn: 0.1057509\ttest: 0.1129314\tbest: 0.1129314 (450)\ttotal: 34m 20s\tremaining: 3m 43s\n",
      "499:\tlearn: 0.1035772\ttest: 0.1120677\tbest: 0.1120657 (498)\ttotal: 38m 18s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1120657244\n",
      "bestIteration = 498\n",
      "\n",
      "Shrink model to first 499 iterations.\n",
      "CPU times: user 38min 23s, sys: 32.2 ms, total: 38min 23s\n",
      "Wall time: 38min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f79e6aa9670>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = CatBoostClassifier(iterations=500, learning_rate=0.03, depth=10)\n",
    "model.fit(features_cb_train, target_cb_train, \n",
    "          eval_set=(features_cb_valid, target_cb_valid),\n",
    "          text_features=['lemmas'], verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера для модели CatBoost составила 0.78\n"
     ]
    }
   ],
   "source": [
    "predictions_cb = model.predict(features_cb_valid)\n",
    "print('F1-мера для модели CatBoost составила {:.2f}'.format(\n",
    "    f1_score(target_cb_valid, predictions_cb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера для модели CatBoost составила 0.78\n"
     ]
    }
   ],
   "source": [
    "predictions_cb = model.predict(features_cb_test)\n",
    "print('F1-мера для модели CatBoost составила {:.2f}'.format(\n",
    "    f1_score(target_cb_test, predictions_cb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнен анализ работы моделей логистической регрессии и CatBoost на классификации текстовых комментариев. Модель логистической регрессии показала более слабый результат, но нужно отметить высокую скорость ее работы. Модель CatBoost показала хороший результат, но потребовала значительные траты времени и ресурсов на обучение. Помимо этого, преимущество модели CatBoost заключается в том, что она работает непосредственно с текстовыми признаками, без необходимости в их векторизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 6609,
    "start_time": "2025-02-08T01:05:29.679Z"
   },
   {
    "duration": 1278,
    "start_time": "2025-02-08T01:05:41.105Z"
   },
   {
    "duration": 248,
    "start_time": "2025-02-08T01:05:58.083Z"
   },
   {
    "duration": 842,
    "start_time": "2025-02-08T01:15:23.060Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-08T01:15:29.979Z"
   },
   {
    "duration": 362,
    "start_time": "2025-02-08T01:16:18.452Z"
   },
   {
    "duration": 142,
    "start_time": "2025-02-08T01:17:09.815Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-08T01:17:19.620Z"
   },
   {
    "duration": 4717,
    "start_time": "2025-02-08T01:19:01.440Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-08T01:19:06.159Z"
   },
   {
    "duration": 861,
    "start_time": "2025-02-08T01:19:06.168Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-08T01:19:07.032Z"
   },
   {
    "duration": 44,
    "start_time": "2025-02-08T01:19:07.041Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-08T01:19:07.086Z"
   },
   {
    "duration": 57,
    "start_time": "2025-02-08T01:19:46.801Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T01:41:06.178Z"
   },
   {
    "duration": 4614,
    "start_time": "2025-02-08T01:41:09.953Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-08T01:41:34.575Z"
   },
   {
    "duration": 873,
    "start_time": "2025-02-08T01:41:35.293Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-08T01:41:36.167Z"
   },
   {
    "duration": 35,
    "start_time": "2025-02-08T01:41:36.500Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-08T01:41:37.125Z"
   },
   {
    "duration": 3150068,
    "start_time": "2025-02-08T01:41:38.624Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-08T02:34:08.694Z"
   },
   {
    "duration": 34,
    "start_time": "2025-02-08T02:34:08.703Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-08T02:34:08.741Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-08T02:34:08.746Z"
   },
   {
    "duration": 84839,
    "start_time": "2025-02-08T02:34:08.751Z"
   },
   {
    "duration": 11,
    "start_time": "2025-02-08T02:35:33.592Z"
   },
   {
    "duration": 31,
    "start_time": "2025-02-08T02:35:33.604Z"
   },
   {
    "duration": 151,
    "start_time": "2025-02-08T02:35:33.637Z"
   },
   {
    "duration": 6670,
    "start_time": "2025-02-08T02:35:33.790Z"
   },
   {
    "duration": 45928,
    "start_time": "2025-02-08T02:35:40.462Z"
   },
   {
    "duration": 86083,
    "start_time": "2025-02-08T02:36:26.394Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-08T02:37:52.478Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-08T02:37:52.508Z"
   },
   {
    "duration": 2057716,
    "start_time": "2025-02-08T02:37:52.538Z"
   },
   {
    "duration": 1068,
    "start_time": "2025-02-08T03:12:10.256Z"
   },
   {
    "duration": 51,
    "start_time": "2025-02-08T12:46:26.692Z"
   },
   {
    "duration": 6938,
    "start_time": "2025-02-08T12:57:07.938Z"
   },
   {
    "duration": 1506,
    "start_time": "2025-02-08T12:57:14.878Z"
   },
   {
    "duration": 907,
    "start_time": "2025-02-08T12:57:16.386Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-08T12:57:17.295Z"
   },
   {
    "duration": 46,
    "start_time": "2025-02-08T12:57:17.310Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-08T12:57:17.358Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.779Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.780Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.781Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.783Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.785Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.786Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.788Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.789Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.791Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.792Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.793Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.795Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.796Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.798Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.799Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-08T13:56:38.801Z"
   },
   {
    "duration": 552695,
    "start_time": "2025-02-09T01:17:04.809Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.506Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.508Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.509Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.511Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.512Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.514Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.515Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.517Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T01:26:17.518Z"
   },
   {
    "duration": 5191,
    "start_time": "2025-02-09T01:26:36.252Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-09T01:26:41.446Z"
   },
   {
    "duration": 938,
    "start_time": "2025-02-09T01:26:41.451Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-09T01:26:42.391Z"
   },
   {
    "duration": 47,
    "start_time": "2025-02-09T01:26:42.401Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-09T01:26:42.450Z"
   },
   {
    "duration": 3461728,
    "start_time": "2025-02-09T01:26:42.460Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-09T02:24:24.189Z"
   },
   {
    "duration": 22,
    "start_time": "2025-02-09T02:24:24.199Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-09T02:24:24.224Z"
   },
   {
    "duration": 21,
    "start_time": "2025-02-09T02:24:24.248Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.271Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.272Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.273Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.274Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.276Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.277Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.278Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.280Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.281Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.282Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T02:24:24.283Z"
   },
   {
    "duration": 97,
    "start_time": "2025-02-09T10:04:56.769Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-09T10:05:45.653Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-09T10:05:54.869Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-09T10:08:37.662Z"
   },
   {
    "duration": 480,
    "start_time": "2025-02-09T10:09:05.928Z"
   },
   {
    "duration": 171,
    "start_time": "2025-02-09T10:09:22.465Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-09T10:13:24.947Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-09T10:13:40.294Z"
   },
   {
    "duration": 56,
    "start_time": "2025-02-09T10:13:44.266Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-09T10:15:23.733Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-09T10:15:33.029Z"
   },
   {
    "duration": 48,
    "start_time": "2025-02-09T10:15:35.919Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-09T10:18:06.234Z"
   },
   {
    "duration": 56,
    "start_time": "2025-02-09T10:18:10.341Z"
   },
   {
    "duration": 1468,
    "start_time": "2025-02-09T10:20:32.274Z"
   },
   {
    "duration": 61,
    "start_time": "2025-02-09T10:20:34.942Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-09T10:21:11.646Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-09T10:21:18.768Z"
   },
   {
    "duration": 622174,
    "start_time": "2025-02-09T10:21:20.516Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-09T10:37:11.456Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-09T10:37:44.078Z"
   },
   {
    "duration": 627697,
    "start_time": "2025-02-09T10:37:44.476Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-09T10:48:12.176Z"
   },
   {
    "duration": 30,
    "start_time": "2025-02-09T10:48:12.190Z"
   },
   {
    "duration": 58,
    "start_time": "2025-02-09T10:54:20.199Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-09T10:54:22.504Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-09T10:54:52.598Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-09T10:55:12.183Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-09T10:55:32.982Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-09T10:55:39.626Z"
   },
   {
    "duration": 50,
    "start_time": "2025-02-09T10:55:42.846Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-09T10:56:18.657Z"
   },
   {
    "duration": 47,
    "start_time": "2025-02-09T10:56:22.164Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-09T10:56:32.580Z"
   },
   {
    "duration": 105253,
    "start_time": "2025-02-09T10:56:34.669Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T10:58:19.924Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-09T10:59:04.587Z"
   },
   {
    "duration": 651146,
    "start_time": "2025-02-09T10:59:05.497Z"
   },
   {
    "duration": 28,
    "start_time": "2025-02-09T11:09:56.650Z"
   },
   {
    "duration": 39,
    "start_time": "2025-02-09T11:20:24.084Z"
   },
   {
    "duration": 42,
    "start_time": "2025-02-09T11:20:47.078Z"
   },
   {
    "duration": 400,
    "start_time": "2025-02-09T11:20:48.516Z"
   },
   {
    "duration": 8062,
    "start_time": "2025-02-09T11:20:50.697Z"
   },
   {
    "duration": 47596,
    "start_time": "2025-02-09T11:21:18.464Z"
   },
   {
    "duration": 56682,
    "start_time": "2025-02-09T11:22:47.075Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T11:23:43.763Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T11:23:43.772Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T11:23:43.773Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T11:23:43.774Z"
   },
   {
    "duration": 0,
    "start_time": "2025-02-09T11:23:43.774Z"
   },
   {
    "duration": 56809,
    "start_time": "2025-02-09T11:25:27.570Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-09T11:27:14.285Z"
   },
   {
    "duration": 32,
    "start_time": "2025-02-09T11:27:15.085Z"
   },
   {
    "duration": 2310583,
    "start_time": "2025-02-09T11:27:15.614Z"
   },
   {
    "duration": 1272,
    "start_time": "2025-02-09T12:05:46.199Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-09T12:05:47.475Z"
   },
   {
    "duration": 1211,
    "start_time": "2025-02-09T12:09:42.038Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
